# 回归
[线性回归模型的概念、原理、代码和应用](https://zhuanlan.zhihu.com/p/80887841)

## 概念

回归是一种用于数值预测的技术，是一种统计学方法, **回归分析统计方法研究变量之间的关系并对其构建模型。**比如：**子辈的平均身高是其父辈平均身高以及他们所处族群平均身高的加权平均和**。**回归模型更像是显示了两个变量的统计关联度**

1. 回归（regression）是一个监督学习（有target的学习）

2. 回归用于预测输入和输出变量的关系，回归问题等价于函数拟合

3. 回归分为学习和预测过程，学习样本规律构建model，预测系统验证学习的model

## 分类
### 线性回归

线性关系，类似2维空间的直线，用一个方程式来表示它，即`Y=a+b*X + e`(Y是因变量，X是自变量)，其中a表示截距，b表示直线的斜率，e是误差项。这个方程可以根据给定的预测变量（s）来预测目标变量的值。

一元线性回归和多元线性回归的区别在于，多元线性回归有（>1）个自变量(x)，而一元线性回归通常只有1个自变量。现在的问题是“我们如何得到一个最佳的拟合线呢？”

**如何获得最佳拟合线（a和b的值）？**最小二乘法

它通过最小化每个数据点到线的垂直偏差平方和来计算最佳拟合线。因为在相加时，偏差先平方，所以正值和负值没有抵消。

1. 概念/过程
   + 损失函数
   + 
2. 基本过程

**要点：**

- 自变量与因变量之间必须有线性关系
- 多元回归存在多重共线性，自相关性和异方差性。
- 线性回归对异常值非常敏感。它会严重影响回归线，最终影响预测值。
- 多重共线性会增加系数估计值的方差，使得在模型轻微变化下，估计非常敏感。结果就是系数估计值不稳定
- 在多个自变量的情况下，我们可以使用向前选择法，向后剔除法和逐步筛选法来选择最重要的自变量。

### 逻辑回归

逻辑回归是用来计算“事件=Success”和“事件=Failure”的概率。当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，我们就应该使用逻辑回归。这里，Y的值从0到1，它可以用下方程表示。

### **多项式回归**

对于一个回归方程，如果自变量的指数大于1，那么它就是多项式回归方程。如下方程所示：

`y=a+b*x^2`

在这种回归技术中，最佳拟合线不是直线。而是一个用于拟合数据点的曲线。



## 过拟合overfit和欠拟合underfit

### 训练误差

### 泛华误差



### 概念

+ overfit（训练量不足）

  训练误差远小于测试数据集的误差

+ underfit（）

  无法得到较低的训练误差（模拟考试很差，真实也很差）

# 卷积神经网络

## 卷积

4\*4 转换为2\*2个单元，每个单元 3\*3

[如何通俗易懂地解释卷积](https://www.zhihu.com/question/22298352)

## 池化层（pooling）

+ max
+ avg

## 多层感知机



# 深度卷积神经网络

# 批量规划

# ReLU 函数

**线性整流函数**（Rectified Linear Unit, **ReLU**），又称**修正线性单元，**是一种[人工神经网络](https://baike.baidu.com/item/人工神经网络)中常用的激活函数（activation function），通常指代以[斜坡函数](https://baike.baidu.com/item/斜坡函数)及其变种为代表的非线性函数。

# 循环神经网络

序列计算概率

解决k-independent 马尔科夫链，即使是k个相互关联，数据还是太大，计算比较

## 梯度计算

优化算法需要梯度，

## 反向传播

反向传播

## 正向传播

# 门控循环单元（GRU）

## R 重置门 gate

+ 捕捉时序数据短期的依赖关系

## Z 更新门

+ 捕捉时序数据中长期的依赖关系

# LSTM 长短期记忆（long short-term memory）



## 输入门 I

## 遗忘门 F

F和I是0~1之间

## 输出门



# 余弦相似度

捕捉2个词之间的相似度

# word2vec

## 模型

### 跳字模型 skip-gram

### 连续词袋模型 CBOW(continuous bag of words ) 

## 训练

### 负采样

### 层序





# 推荐系统

1. 

两种推荐系统：

+ 协同过滤
  + 用户行为 U2U2I
  + 物品行为 U2I2I

+ 基于内容

## 召回路径

1. i2i：计算item-item相似度，用于相似推荐、相关推荐、关联推荐；
2. u2i：基于矩阵分解、协同过滤的结果，直接给u推荐i；
3. u2u2i：基于用户的协同过滤，先找相似用户，再推荐相似用户喜欢的item；
4. u2i2i：基于物品的协同过滤，先统计用户喜爱的物品，再推荐他喜欢的物品；
5. u2tag2i：基于标签的泛化推荐，先统计用户偏好的tag向量，然后匹配所有的Item，这个tag一般是item的标签、分类、关键词等tag；

 

## 接口

input：

+ 用户id
+ 场景id
+ 物品id
+ 环境信息
+ 分页参数

output

+ 物品列表
+ 分桶id 代表推荐算法 比如内容过滤
+ eventid  跟踪单词推荐点击
+ 分页信息

精度/精确率和召回率是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。

## 聚类推荐

根据用户的聚类id推荐，不够个性化



##  多路召回

融合排序

召回策略：

+ 实时召回 u2I2I
+ 基于内容 U2TAG2I  泛华效果比较好
+ 矩阵分解 U2I (user 矩阵 和item进行叉乘)
+ 聚类推荐 U2U2I

粗排：

+ 减低后续的计算量，融合排序 topN

精排

+ 非必需品
+ 将粗排截断交给精排
+ 按顺序展示，
+ 结合CTR



精排策略

+ 顺序
+ 平均
+ 加权平均
+ 动态加权   展示日志和CTR
  + 点击数/展现数
+ 机器学习权重

## 精度/精确率

精度是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率

Precision就是检索出来的条目（比如：文档、网页等）有多少是准确的

提取出的正确信息条数 / 提取出的信息条数 

## 召回率

召回率是指**检索出的相关**文档数和文档库中**所有的相关文档数**的比率，衡量的是检索系统的查全率

Recall就是**所有准确的条目有多少被检索出来**了。



这就好比推荐系统根据你的喜好，推荐了10个商品，其中真正相关的是5个商品。在所有商品当中，相关的商品一共有20个，那么

k精度 = 5 / 10

k召回 = 5 / 20